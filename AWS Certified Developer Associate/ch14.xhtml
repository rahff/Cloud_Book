<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:svg="http://www.w3.org/2000/svg" lang="en" xml:lang="en">
<head>
<title>AWS Certified Developer Associate All-in-One Exam Guide (Exam DVA-C01)</title>
<link href="1260460177.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:c4d348f1-9c3d-457f-b76a-654174c9fde1" name="Adept.expected.resource"/>
</head>
<body>
<section epub:type="chapter">
<h2 class="h2c" id="ch14"><span epub:type="pagebreak" id="page_371"/><span class="chap">CHAPTER <span class="chap1">14</span></span></h2>
<h2 class="h2c1">AWS NoSQL Database Service: Amazon DynamoDB</h2>
<p class="noindent">In this chapter, you will learn</p>
<p class="bulleta">• DynamoDB components</p>
<p class="bulleta">• NoSQL vs. SQL comparison</p>
<p class="bulleta">• DynamoDB Accelerator (DAX)</p>
<p class="bulleta">• DynamoDB Local and Web</p>
<p class="bulleta">• Logging and monitoring</p>
<p class="bulleta">• Data protection</p>
<p class="hr"/>
<p class="noindentb">This chapter will discuss how the AWS NoSQL database service, DynamoDB, works and its configuration and access.</p>
<h3 class="h3" id="ch14lev1sec1">Amazon DynamoDB</h3>
<p class="noindent">Amazon DynamoDB is a managed NoSQL database offering low latency, high performance, and seamless scalability. DynamoDB handles the cluster setup, configuration, replication, backup, hardware provisioning, and software patching. Since DynamoDB handles the encryption of your data at rest, you don’t need to encrypt the data manually and manage the encryption/decryption process. DynamoDB allows you to create database tables where you can store huge volumes of data and retrieve it easily. It can quickly scale up and down and serve massive traffic requests without any performance issue or downtime.</p>
<p class="indent">The DynamoDB table performance metrics, in addition to resource utilization monitoring, can be viewed in the AWS Management Console. You can create a full backup of your DynamoDB tables using on-demand backup for short-term or long-term retention. You can protect your DynamoDB tables from accidental deletion and incorrect write operations by enabling point-in-time recovery up to 35 days. <span epub:type="pagebreak" id="page_372"/>When you store a very large volume of session data, event logs, usage patterns, and other temporary data in DynamoDB tables, you can enable Time to Live (TTL) with the Expiration Time set to automatically delete the obsolete data. Amazon DynamoDB uses solid-state disks (SSD) for high performance while automatically replicating the data across multiple Availability Zones to provide high availability. The data is automatically spread across multiple servers to handle high throughput, and global tables are replicated and spread over multiple AWS regions. The core components of DynamoDB are as follows:</p>
<p class="bullett">• <strong>Tables</strong>   A collection of data that stores data in tables and is schema-less, so you do not need to define attributes or its data types beforehand.</p>
<p class="bulleta">• <strong>Items</strong>   A group of unique attributes, and every table can have zero or more items. An item can have a nested attribute up to 32 levels deep.</p>
<p class="bulleta">• <strong>Attributes</strong>   A basic data element that cannot be broken down further, and one or more attributes are contained in each item. An attribute can have only one value, which can be strings, binary, or numbers.</p>
<p class="bulleta">• <strong>Primary key</strong>   Uniquely identifies every item, and no two items can have the same key in a table.</p>
<p class="bulleta">• <strong>Partition key</strong>   Contains a single attribute, which is used as input to an internal hash function, and the output determines the physical partition of the item. When a table has only a partition key, then no two items can have the same key value.</p>
<p class="bulleta">• <strong>Composite primary key</strong>   A combination of partition key and sort key, where the two items can have the same partition key but with different sort key values.</p>
<p class="bulleta">• <strong>Hash attribute</strong>   The partition key item used for internal hash functions to evenly distribute data items across partitions.</p>
<p class="bulleta">• <strong>Range attribute</strong>   The sort key item used to store items with the same partition key physically close together in sorted order.</p>
<p class="bulleta">• <strong>Secondary index</strong>   Allows you query using an alternative key in addition to the primary key, and you can have one or more secondary indexes on a table.</p>
<p class="bulleta">• <strong>Global secondary index</strong>   Contains a partition key and a sort key that can be different from the indexes on the table.</p>
<p class="bulleta">• <strong>Local secondary index</strong>   Contains the same partition key as in the table, but can have a different sort key.</p>
<p class="bulleta">• <strong>DynamoDB streams</strong>   Capture all data modification events, like when a new item is added, updated, or deleted in DynamoDB tables in near-real time. Streams are represented by a system record, and DynamoDB writes it in the order in which the events occurred. The DynamoDB stream contains a table name and timestamp with a lifetime of 24 hours.</p>
<h3 class="h3" id="ch14lev1sec2"><span epub:type="pagebreak" id="page_373"/>Data Types</h3>
<p class="noindent">DynamoDB is a schema-less NoSQL database where you do not have to define any attributes or data types when you create tables. DynamoDB offers the following data types:</p>
<p class="bullett">• <strong>Scalar Types</strong>   Binary, Boolean, string, null, and number.</p>
<p class="bulleta">• <strong>Document Types</strong>   It is a nested structure in JSON format represented as a list, which is an ordered collection of values enclosed in [ ], and maps, which is an unordered collection of name value pairs enclosed in { }.</p>
<p class="bulleta">• <strong>Set Types</strong>   It is represented as sets of numbers, strings, and binary.</p>
<h3 class="h3" id="ch14lev1sec3">Control Plane Operations</h3>
<p class="noindent">Control plane operations are similar to Data Definition Language (DDL) in SQL that allow you to create and manage DynamoDB tables, indexes, and streams.</p>
<p class="bullett">• <strong>CreateTable</strong>   Creates tables, indexes, and enable streams.</p>
<p class="bulleta">• <strong>DescribeTable</strong>   Fetches primary key schema, throughput settings, and index information.</p>
<p class="bulleta">• <strong>ListTables</strong>   Fetches the names of all DynamoDB tables, and an array of the table names of the current account and endpoint is returned.</p>
<p class="bulleta">• <strong>UpdateTable</strong>   Creates, updates, and removes indexes in addition to modifying DynamoDB streams.</p>
<p class="bulleta">• <strong>DeleteTable</strong>   Deletes the DynamoDB table and its dependent objects.</p>
<h3 class="h3" id="ch14lev1sec4">Data Plane Operations</h3>
<p class="noindent">Data plane operations, also called CRUD (create, read, update, delete), is similar to the Data Manipulation Language (DML) in terms of create, read, update, and delete operations on data from a DynamoDB table.</p>
<p class="bullett">• <strong>Create<br/>PutItem and BatchWriteItem</strong>   You can write a single item to your DynamoDB table using PutItem and write up to 25 items using BatchWriteItem, which is more efficient because it uses only a single network round trip to write the items.</p>
<p class="bulleta">• <strong>Read<br/>GetItem and BatchGetItem</strong>   You can retrieve a single item from your DynamoDB table using GetItem and retrieve up to 100 items using BatchGetItem, which is more efficient because it uses only a single network round trip to read the items.</p>
<p class="bulletn"><strong>Query and Scan</strong>   You can retrieve all items or subsets based on your partition key using Query, and you can retrieve all items or subsets from your table or index using Scan.</p>
<p class="bulleta">• <span epub:type="pagebreak" id="page_374"/><strong>Update<br/>UpdateItem</strong>   You can modify one or more attributes based on the primary key for the item in addition to performing conditional updates when a condition is met.</p>
<p class="bulleta">• <strong>Delete<br/>DeleteItem and BatchWriteItem</strong>   You can delete a single item from your DynamoDB table using DeleteItem and delete up to 25 items using BatchWriteItem from one or more tables.</p>
<p class="bulleta">• <strong>Streams<br/>ListStreams</strong>   You can list streams of a particular table or list all your streams using ListStreams.</p>
<p class="bulletn"><strong>DescribeStream</strong>   You can get information (i.e., metadata) about your stream using DescribeStream.</p>
<p class="bulletn"><strong>GetShardIterator</strong>   This returns the data structure (i.e., shard iterator) from the stream.</p>
<p class="bulletn"><strong>GetRecords</strong>   Using shard iterator, it retrieves one or more stream records.</p>
<h3 class="h3" id="ch14lev1sec5">SQL vs. NoSQL</h3>
<p class="noindent">Structured Query Language (SQL) is used by the traditional relational database management system (RDBMS) to store structured data. Not Only SQL (NoSQL) is used in a nonrelational database to store unstructured data. The following table compares how they each perform common database tasks.</p>
<p class="imaget1"><img alt="images" src="t0374-01.jpg"/></p>
<p class="imageta"><span epub:type="pagebreak" id="page_375"/><img alt="images" src="t0375-01.jpg"/></p>
<h3 class="h3" id="ch14lev1sec6">DynamoDB Transactions</h3>
<p class="noindent">DynamoDB transactions offer atomicity, consistency, isolation, and durability (ACID) properties to maintain integrity of your data.</p>
<p class="bullett">• <strong>TransactWriteItems</strong>   DynamoDB offers Put, Update, and Delete batch operations.</p>
<p class="bulletb">• <strong>TransactGetItems</strong>   DynamoDB offers Get batch operations.</p>
<p class="indent">Amazon DynamoDB transactions can be enabled for adding, updating, or deleting multiple complex items as a single or all-or-nothing transaction with no additional cost, and you pay only for the reads or writes of your transaction. There will be two reads or writes of every record in the transaction; the first one is to prepare, and the second is to commit the transaction, which can be viewed in the Amazon CloudWatch metrics. You can group up to 25 write actions in a single all-or-nothing transaction atomically, so either all succeed or all are rolled back (do not succeed). You can use Put that initiates a PutItem to either create a new item or replace an old item. You can use Update to initiate an UpdateItem to edit an existing item or add a new item if it is not available. You can use Delete to initiate a DeleteItem to delete a single transaction. As soon as the transaction is completed, all the transaction changes are replicated to global secondary indexes (GSIs), streams, and backups. You can use Get to initiate a GetItem to fetch the data item based on the primary key.</p>
<h4 class="h4" id="ch14lev2sec1"><span epub:type="pagebreak" id="page_376"/>Read Consistency</h4>
<p class="noindent">DynamoDB provides strong read consistency and eventual read consistency. The DynamoDB sends the HTTP 200 response (OK) when the write is completed to your application. When you read data from a DynamoDB table and the response contains some stale data, it is known as eventual read consistency. When your request returns only the committed data, it is known as strong consistency. Strongly consistent reads might have higher latency, since they are read from the physical table.</p>
<h4 class="h4" id="ch14lev2sec2">Read/Write Capacity Mode</h4>
<p class="noindent">Amazon DynamoDB offers on-demand and provisioned read and write capacity modes. When using the on-demand mode, DynamoDB quickly scales up or down based on the workload, which can be used for both new and existing tables without changing code. When using the provisioned mode, you can specify the number of reads and writes per second for your application and use auto-scaling to respond to any future traffic changes.</p>
<div class="siden">
<p class="imagen"><img alt="Images" class="inlinen" src="examtip.jpg"/></p>
<p class="note"><strong>EXAM TIP</strong>   Eventually consistent read is preferred by DynamoDB, unless you update the configuration. When you use the ConsistentRead parameter with GetItem, Query, and Scan read operations, DynamoDB uses strongly consistent reads.</p>
</div>
<h4 class="h4" id="ch14lev2sec3">Isolation Levels</h4>
<p class="noindent">Isolation levels are an important concept to understand before configuring your transactions in DynamoDB or on any other database. DynamoDB provides a serializable isolation level to make sure the output of your multiple concurrent operations display the same results as if this is the only transaction taking place. No other transactions take place until this finishes. DynamoDB provides a read-committed isolation level to make sure the read always returns committed data and will not prevent changes to the data after the read. Whenever there is a concurrent item-level request on the same item within a transaction, then a transactional conflict will happen. For example, a PutItem for a data item can conflict with another TransactWriteItems on the same data item. The transactional conflict can be captured with CloudWatch as a TransactionConflict metric of the failed item-level requests.</p>
<h3 class="h3" id="ch14lev1sec7">DynamoDB Accelerator</h3>
<p class="noindent">Amazon DynamoDB Accelerator (DAX) is designed for read-intensive applications that require responses from single-digit milliseconds to microseconds that run within your Amazon Virtual Private Cloud (VPC) environment. DAX clusters can be launched in your VPC using the AWS Management Console, and you can use security groups to control access to your DAX clusters. You just need to deploy your application that needs access to DAX in an EC2 instance with a DAX client in the same Amazon VPC. The DAX client sends all requests to the DAX cluster (called a cache hit when the items are available in DAX), and it sends the request to DynamoDB only if the items are not <span epub:type="pagebreak" id="page_377"/>available in the DAX cluster (called a cache miss when the items are not available in DAX, so the response from DynamoDB is written to the DAX primary node and DAX returns the response to the application).</p>
<h4 class="h4" id="ch14lev2sec4">DAX Components</h4>
<p class="noindent">A DAX cluster may consist of one or more nodes, and each node runs its own cashing DAX instance. The nodes can be a primary node or read replica node of the cluster. DAX can be accessed using its endpoint, and it performs load balancing and routing to evenly distribute the incoming requests across all of the nodes in the cluster.</p>
<h4 class="h4" id="ch14lev2sec5">DAX Read</h4>
<p class="noindent">When your application requests items with strong consistent reads, DAX sends it to DynamoDB and returns the results to the application without saving it on DAX. Any write requests from your application are sent to DynamoDB directly, and the DAX cluster is updated only after a successful write on DynamoDB. When your application tries to create or update a table, it is performed directly on the DynamoDB, not on the DAX. All the results from GetItem and BatchGetItem are stored in a cache for a duration based on its TTL value using its primary key in DAX. When your application sends the request, the items are read directly from the cache and return the result to your application. A timestamp is assigned to each item in the cache and items expire based on the TTL value. If the incoming application request is on any expired item, DAX sends it to DynamoDB because it’s considered a cache miss.</p>
<h4 class="h4" id="ch14lev2sec6">DAX LRU</h4>
<p class="noindent">By default, the well-known least recently used (LRU) algorithm is also used in the DAX cache so when the cache becomes full, DAX evicts older LRU items even if they have not yet expired in order to make space for new items; this feature is not configurable. DAX also maintains a cache that stores the result sets from queries and scans based on their parameter values. The query or scan request from an application uses this cache to return the results based on its parameter values. DAX returns the results to your application immediately when a cache hit occurs (i.e., the result set is found in the query cache). DAX sends the request to DynamoDB when a cache miss occurs (i.e., the result set is not found in the query cache). The return query result from DynamoDB is stored in DAX and a return response is sent back to your application. The LRU algorithm is applied to the query cache as well by default, and this is not configurable.</p>
<h4 class="h4" id="ch14lev2sec7">DAX Cluster and Nodes</h4>
<p class="noindent">A DAX cluster is a logical group of more than one node, where one node is assigned as the primary node. A node is the building block that runs an instance of the DAX along with a single replica. You can add one or more nodes to your DAX cluster to increase the overall read throughput, or you can use a larger node with more capacity that increases throughput in a different DAX cluster because each DAX cluster can contain only nodes <span epub:type="pagebreak" id="page_378"/>of the same type. The primary node responds to application requests for cached data, handles the write operations, and evicts data from the cache based on the LRU or TTL in addition to replicating the data changes to all of the replica nodes. The replica provides read-scaling and automatically fails over to become the new primary node. AWS recommends using at least three nodes by placing each node in different Availability Zones to make your DAX cluster fault-tolerant. The DAX cluster is completely isolated from other AWS regions, and it can interact with the DynamoDB tables that are in the same region, so you need to provision a new DAX cluster in another region if you have DynamoDB tables in more than one region.</p>
<h4 class="h4" id="ch14lev2sec8">DAX Control</h4>
<p class="noindent">Similar to Amazon RDS parameter groups, you can use parameter groups to optimize performance using set of parameters applied to a cluster. All the nodes in the cluster share the same parameter group and are configured in the same way. A DAX cluster uses a security group as its virtual firewall to control inbound network traffic, and since security groups are stateful, the same ingress rule that you add to your security group to allow incoming network traffic applies to outgoing network traffic by default. The DAX cluster has an Amazon Resource Name (ARN)—arn:aws:dax:us-east-1:1234567890:cache/my-dax-cluster—that can be used in an Identity and Access Management (IAM) policy to grant fine-grained access permissions for your DAX cluster. Both the DAX cluster and node have an endpoint—for example, my-dax-cluster.cache.amazonaws.com:8111—to use in your application; however, AWS recommends using a DAX cluster endpoint instead of a node endpoint because your application does not need to keep track of adding or removing nodes from the cluster. You need to monitor DAX events like success or failure when you add a node or make changes to any configurations (e.g., security groups). An Amazon Simple Notification Service (SNS) topic can be configured to immediately notify you when any event occurs in your DAX cluster.</p>
<h4 class="h4" id="ch14lev2sec9">DAX Write</h4>
<p class="noindent">DAX can be used for TransactWriteItems and TransactGetItems in DynamoDB. When you use TransactWriteItems through DAX, the return response using TransactGetItems is populated after the write. When using DAX, you use two read capacity units (RCUs) for every item in the TransactWriteItems transaction. As a best practice, you can either enable automatic scaling or provision enough throughput capacity for two read or write operations for each item in your transaction. AWS recommends splitting up meaningful simple transactions to improve throughput instead of grouping multiple distinct transactions. Follow data-modeling best practices to avoid multiple transactions updating the same data concurrently, which leads to cancelled transactions. You can use DAX caching, which provides fast in-memory performance to your applications from single-digit milliseconds to microsecond response times and requires very minimal changes to your application.</p>
<h4 class="h4" id="ch14lev2sec10"><span epub:type="pagebreak" id="page_379"/>DAX Encryption</h4>
<p class="noindent">DAX provides encryption at rest using server-side encryption. In addition, DAX provides microsecond latency by allowing access to eventually consistent data from DynamoDB tables. DAX is ideal for applications that need quick response times for reads, applications that read more frequently, read-intensive applications, and applications that read large sets of data repeatedly. DAX may not be ideal for applications that expect strong consistent reads, applications that are write-intensive, and applications that are not read-intensive.</p>
<h3 class="h3" id="ch14lev1sec8">Auto-Scaling</h3>
<p class="noindent">DynamoDB offers auto-scaling where you define the upper and lower limits for your read and write capacity needs. When you enable auto-scaling, DynamoDB increases or decrease its provisioned read and write capacity to handle a sudden increase or decrease in traffic. Similar to reserved EC2 instances, you can purchase the DynamoDB reserved capacity in advance, where you need to commit to and pay up-front for your read and write capacity units, which offers you a huge cost savings instead of using on-demand provisioned mode.</p>
<h3 class="h3" id="ch14lev1sec9">Data Distribution</h3>
<p class="noindent">When you create an Amazon DynamoDB table, the data is stored in partitions in SSDs and replicated across multiple Availability Zones in a single AWS region. Amazon DynamoDB handles the partition management automatically and takes care of your applications’ provisioned throughput requirements. The global secondary indexes in your DynamoDB are stored separately from the data in partitions. The data is stored in DynamoDB based on the key—if your table contains only a simple primary key, it stores and retrieves the data using the partition key value; if your table contains a composite primary key, DynamoDB uses both the partition key and sort key to store and retrieve your data.</p>
<h3 class="h3" id="ch14lev1sec10">DynamoDB Local</h3>
<p class="noindent">AWS also offers a downloadable version of DynamoDB to save on provisioned throughput, data storage, and data transfer fees, which allows you to write and test applications without accessing the DynamoDB web service or using an Internet connection. You can access DynamoDB running locally by using <span class="code">--endpoint-url</span> as shown:</p>
<p class="imagep"><img alt="images" src="p0379-01.jpg"/></p>
<p class="indent">You can either use the -sharedDb option or -inMemory option while creating the DynamoDB database locally. When you use the -sharedDb option, the data is stored in the shared-local-instance.db file, and when you use the -inMemory option, all data is written to memory and is not stored locally. You can use the downloadable version of <span epub:type="pagebreak" id="page_380"/>DynamoDB for development and testing purposes, and you should use the DynamoDB web service for production, which provides availability, durability, and scalability in addition to Amazon managing the DynamoDB for you.</p>
<p class="indent">The CreateTable table requires provisioned throughput settings, but it is ignored in downloadable DynamoDB. Scan operations are performed sequentially instead of parallel scans. The speed of read and write operations on table data is limited only by the speed of your machine. Read operations are eventually consistent, but might appear to be strongly consistent. Item collection metrics and sizes are not tracked in downloadable DynamoDB.</p>
<h3 class="h3" id="ch14lev1sec11">DynamoDB Web</h3>
<p class="noindent">Amazon DynamoDB can be accessed through the AWS Management Console or AWS Command Line Interface (CLI). From the console, you can create, update, or delete tables; manage streams; monitor alerts; and monitor the capacity and health of the DynamoDB database. You can add, view, scan, query, update, or delete items from the DynamoDB table. Amazon DynamoDB table names are case sensitive in the DynamoDB web service. For example, a table named KAMESH and another one named kamesh can both coexist as separate tables in the DynamoDB web service. However, with the downloadable Amazon DynamoDB, table names are case insensitive, so you will get an error if you try creating a table name of JACK and another table name of jack.</p>
<h3 class="h3" id="ch14lev1sec12">Secondary Indexes</h3>
<p class="noindent">Secondary indexes support your query operations when performing an index scan to retrieve the data instead of a table scan (i.e., querying the entire table). You can create multiple secondary indexes, but they are associated with a single table called a base table. You can also create an alternative key using a partition key and sort key for the index. The following are the two types of secondary indexes allowed in DynamoDB:</p>
<p class="bullett">• <strong>Global secondary index (GSI)</strong>   Where the partition key and a sort key can be different from the base table and the index spans across all partitions. The read and write capacity must be specified separately.</p>
<p class="bulleta">• <strong>Local secondary index (LSI)</strong>   Where the partition key must be the same as the base table, but with a different sort key, and the index has the same partition key value. The read and write capacity of the base table is used.</p>
<h3 class="h3" id="ch14lev1sec13">DynamoDB Stream</h3>
<p class="noindent">The DynamoDB stream provides a stream of information about all the changes to your data in a DynamoDB table. Similar to triggers in the traditional relational database, the DynamoDB stream captures data whenever you create, update, or delete data items from the table. A stream can capture the before or after images of your data items. DynamoDB streams appear in the same sequence as the actual modifications and appear only once <span epub:type="pagebreak" id="page_381"/>in near-real time. DynamoDB streams have separate endpoints, and you can use <a href="http://streams.dynamodb.us-east-1.amazonaws.com">streams.dynamodb.us-east-1.amazonaws.com</a> to access DynamoDB streams. DynamoDB streams can be enabled while creating a new table or added to an existing table without any performance impact and receive a unique ARN. A stream consists of modification records that are organized into shards, which contain multiple stream records, and they are removed automatically after 24 hours.</p>
<h3 class="h3" id="ch14lev1sec14">Backup and Recovery</h3>
<p class="noindent">You can perform an on-demand backup of your DynamoDB database without any performance impact or additional cost; however, you pay for the backup storage cost. You can perform a point-in-time recovery from the backup using EarliestRestorableDateTime (35 days) or LatestRestorableDateTime (5 minutes), which protects you from accidental delete or write operations and can be stored for a long time to satisfy your audit or compliance requirements. The backups can be kept even after the original table in the same region is deleted, and it will not consume the provisioned throughput of your table. You can use either AWS Lambda or AWS Backup to schedule your backup, but don’t forget to periodically delete the old backups. When you restore a table, the provisioned read and write capacity of original table is set to the new restored table in addition to any LSIs and GSIs. If you have enabled AWS CloudTrail then all your backup and recovery actions will be captured for monitoring and auditing.</p>
<h3 class="h3" id="ch14lev1sec15">DynamoDB Global Tables</h3>
<p class="noindent">This is a fully managed multiregion solution, and you just need to specify the AWS regions where you want the DynamoDB table, and the identical tables are created in those regions, and all your data changes are replicated to them. DynamoDB global tables use the TTL feature to replicate the TTL deletes to all replica tables. However, ACID is guaranteed only within the region and is not supported across regions in global tables because the data changes will be replicated to other regions only after they are committed in the original region.</p>
<h3 class="h3" id="ch14lev1sec16">NoSQL Workbench</h3>
<p class="noindent">The NoSQL Workbench is in preview at this time, and AWS recommends using the preview release tools or services for nonproduction environments, not in your production environments. NoSQL Workbench is a cross-platform client-side application available for Windows and macOS. It can be used for data modeling, data visualization, creating, querying, and managing your DynamoDB tables. NoSQL Workbench for DynamoDB can be used to build new data models using your existing data models, and you can also import and export the data model. NoSQL Workbench can be used as a data model visualizer to see the access patterns of your query mapping without writing code. You can manually add data or import data to your data model. You can use the graphical user interface to view and query your DynamoDB tables.</p>
<h3 class="h3" id="ch14lev1sec17"><span epub:type="pagebreak" id="page_382"/>Data Protection</h3>
<p class="noindent">Your data is stored on multiple nodes across multiple Availability Zones in an Amazon region. The user data stored at rest and data in transit are protected with encryption because often the company policies, industry or government regulations, and compliance or audit requirements require this. All user data that is stored in durable media, including primary key, local and global secondary indexes, streams, global tables, backups, and DAX clusters, is encrypted at rest using encryption keys stored in AWS Key Management Service (KMS). During the creation of a new table, you can choose the AWS-owned customer master key (CMK), which is the default encryption type where the key is owned by DynamoDB with no additional charge. Or you can choose the AWS-managed CMK, where the key is stored in your account and managed by AWS KMS, so the charges apply for this type of encryption. Or you can choose a customer-managed CMK, where the key is stored in your account and owned, created, and managed by you and AWS KMS charges still apply. DynamoDB decrypts data when you access an encrypted table. The encryption key can be switched from the AWS-owned CMK to AWS-managed CMK to customer-managed CMK without changing your application code. Amazon DynamoDB uses the 256-bit Advanced Encryption Standard (AES-256) to secure your data from any unauthorized access, and you can encrypt only the entire table, not a subset of items in a table.</p>
<p class="indent">When you use AWS-owned CMKs, the key is not stored in your AWS account. AWS owns and manages the CMKs to protect your data, so you don’t have the ability to view or audit key use. You don’t need to create, manage, and rotate the key regularly to protect the keys, and you are not charged a monthly fee or a usage fee with AWS-owned CMKs.</p>
<p class="indent">You can use AWS-managed CMKs where the CMKs are in your account but they are created and managed on your behalf by AWS. AWS-managed CMKs can be viewed, including key policies, and you can audit the key usage from AWS CloudTrail logs. Even though you own the AWS account and KMS key, you cannot manage or change CMKs permissions because AWS creates and manages the key for you. You will incur AWS KMS charges, since it uses your key.</p>
<p class="indent">You can also use customer-managed CMKs where you create, own, and manage the CMKs in your AWS account. You have full responsibility and control over these CMKs and you need to establish and maintain the key policies, IAM policies, and rotating cryptographic material. When you delete or update the encryption key, any read or write operations are prevented on the table, the table status is changed to Inaccessible, and you receive an email notification. You must provide a new encryption key with DynamoDB access within seven days. You incur AWS KMS charges for using your own KMS key.</p>
<p class="bullett">• <strong>Data in transit</strong>   All data in transit is encrypted, except DAX data, and the to-and-from communication uses the HTTPS protocol with Secure Sockets Layer (SSL)/Transport Layer Security (TLS) encryption to protect your data in transit.</p>
<p class="bulletb">• <strong>Data in use</strong>   You can use your existing client-side encryption to encrypt your data before sending it to DynamoDB.</p>
<p class="indent"><span epub:type="pagebreak" id="page_383"/>The DynamoDB streams and backups are encrypted, and the LSIs and GSIs are encrypted using a base table encryption key. You can use the AWS-owned CMK or AWS-managed CMK to encrypt global tables.</p>
<h3 class="h3" id="ch14lev1sec18">Maintenance Window</h3>
<p class="noindent">The DAX cluster has a weekly maintenance window to apply system changes, and DAX assigns a 60-minute window randomly if the preferred window is not assigned during the creation or modification of your cluster. AWS recommends selecting a maintenance window during the lowest usage of your DAX cluster and its nodes.</p>
<h3 class="h3" id="ch14lev1sec19">Logging and Monitoring</h3>
<p class="noindent">Monitoring is an important part of any solution that you build, and you should collect monitoring data from DynamoDB so that you can debug any failure. You need to establish a baseline for normal DynamoDB performance based on various times and load conditions. This will be compared with the current performance to find any anomalies. The baseline should contain the number of read or write capacity units consumed over the specified time period. It also should contain the requests that exceeded a table’s provisioned write or read capacity during the specified time period.</p>
<p class="indent">Here’s a list of the monitoring tools:</p>
<p class="bullett">• <strong>Amazon CloudWatch</strong>   DynamoDB can be monitored using CloudWatch, which collects the near-real-time metrics automatically. You can retain these statistics for a certain duration based on your requirements for comparing application performance. You can keep track of the TTL deletions by monitoring TimeToLiveDeletedItemCount for a certain period. You can track provisioned throughput by monitoring ConsumedReadCapacityUnits or ConsumedWriteCapacityUnits for a certain period. You can find which event is throttling your request by comparing ThrottledRequests with ReadThrottleEvents and WriteThrottleEvents metrics. Normally, the SystemErrors should return zero, and it can be monitored to find any request returns server error (i.e., HTTP 500) to investigate further. AWS CloudTrail captures all DynamoDB application programming interface (API) calls as events, which can be continuously delivered to an Amazon S3 bucket to help you find who made the request and when the request was made.</p>
<p class="bulleta">• <strong>Amazon CloudWatch Alarms</strong>   You can create alarms based on metrics and monitor them over a time to perform an action based on the threshold value. The action can be an Amazon SNS notification or auto-scaling. CloudWatch alarms are triggered when the state is changed and during a specified time period.</p>
<p class="bulleta">• <strong>Amazon CloudWatch Logs</strong>   Monitor, store, and access your log files.</p>
<p class="bulleta">• <span epub:type="pagebreak" id="page_384"/><strong>Amazon CloudWatch Events</strong>   When an event occurs, route it to one or more target streams or functions and take the appropriate corrective action.</p>
<p class="bulleta">• <strong>AWS CloudTrail Log Monitoring</strong>   You can share log files, monitor CloudTrail log files, and validate whether log files have changed after delivery.</p>
<h3 class="h3" id="ch14lev1sec20">Infrastructure Security</h3>
<p class="noindent">All DynamoDB API calls are captured in AWS CloudTrail. AWS recommends using TLS 1.2 and clients that support the Ephemeral Diffie-Hellman (DHE) or Elliptic Curve Diffie-Hellman Ephemeral (ECDHE) cipher. All requests must be authenticated using an IAM access key ID and a secret access key, or use AWS Security Token Service (STS) to generate temporary sign-in security credentials. It is a good practice to use a Virtual Private Cloud (VPC) endpoint for DynamoDB to enable Amazon EC2 instances in your VPC to use their private IP addresses to access DynamoDB with no exposure to the public Internet.</p>
<p class="indent">When you use Amazon VPC to launch the DAX cluster and your application, it offers full control over the IP range, subnets, and security groups. The to-and-from network communication to your DynamoDB uses HTTPS, which uses SSL/TLS encryption protection. You can avoid privacy and security concerns by using an IPSec virtual private network (VPN) tunnel to route your network traffic instead of using the Internet. In addition, you can use VPC endpoints for DynamoDB so the traffic between your VPC endpoint and DynamoDB service does not leave the Amazon network and is not exposed to the public Internet.</p>
<h3 class="h3" id="ch14lev1sec21">Security Best Practices</h3>
<p class="bullett">• <strong>Encryption at rest</strong>   DynamoDB data is stored in tables, indexes, and streams, and is encrypted using AWS-owned or AWS-managed KMS key to protect the data from unauthorized access.</p>
<p class="bulleta">• <strong>Use IAM roles</strong>   Use an IAM role for your users and applications to obtain temporary access keys to access DynamoDB instead of storing AWS credentials directly in the application.</p>
<p class="bulleta">• <strong>Use IAM policies</strong>   Implement the least access privilege policy that reduces security risk and impact, where users get only the absolutely required permissions to perform their operations on DynamoDB by using AWS- or customer-managed policies.</p>
<p class="bulleta">• <strong>Fine-grained access</strong>   DynamoDB allows you to control fine-grained access by granting only read-only or write-only access to certain items and attributes in a table or a secondary index based on the role of the user.</p>
<p class="bulleta">• <strong>VPC endpoint</strong>   This prevents traffic from traversing the public Internet and allows you to control and limit access to the DynamoDB table.</p>
<p class="bulleta">• <span epub:type="pagebreak" id="page_385"/><strong>Client-side encryption</strong>   Use the Amazon DynamoDB Encryption Client software library to encrypt your data before sending it to DynamoDB.</p>
<p class="bulleta">• <strong>Use AWS CloudTrail</strong>   Use CloudTrail logs to audit all AWS KMS requests for when and what operation used the CMK, who requested it from which IP address, and so on.</p>
<p class="bulleta">• <strong>Control-plane operations</strong>   You can use CloudTrail to obtain important information about who and when a DynamoDB was created, updated, or deleted to track table changes made to your tables, indexes, and streams.</p>
<p class="bulleta">• <strong>Data-plane operations</strong>   Use the Amazon DynamoDB stream to log and monitor data-plane operations, like GetItem and PutItem, and trigger a Lambda function to send a notification.</p>
<p class="bulleta">• <strong>DynamoDB configuration</strong>   Use AWS Config to continuously monitor any DynamoDB configuration changes and trigger an Amazon SNS notification.</p>
<h3 class="h3" id="ch14lev1sec22">Chapter Review</h3>
<p class="noindent">This chapter began with an introduction to Amazon DynamoDB, which is the NoSQL offering from AWS. It then introduced all the Amazon DynamoDB core components and how the cluster setup, configuration, replication, backup, hardware provisioning, and software patching are handled in Amazon DynamoDB. It discussed the control-plane operations that allow you to create and manage DynamoDB tables, indexes, and streams and data-plane operations that create, read, update, and delete data from a DynamoDB table. Since most of us are familiar with SQL, the chapter explained in detail with code the differences between SQL and NoSQL databases. DynamoDB transactions offer ACID properties to maintain integrity of your data. Isolation levels are an important concept to understand before configuring your transactions in DynamoDB or on any other database. DynamoDB provides a serializable isolation level to make sure the output of your multiple concurrent operations displays the same results as if this were the only transaction taking place and no other transactions occur until this finishes.</p>
<p class="indent">Amazon DAX is designed for read-intensive applications that require responses from single-digit milliseconds to microseconds that run within your Amazon VPC environment. DAX clusters can be launched in your VPC using the AWS Management Console, and you can use security groups to control access to your DAX clusters. You just need to deploy your application that needs access to DAX in an EC2 instance with the DAX client in the same Amazon VPC. The DAX client sends all requests to the DAX cluster (called a cache hit when the items are available in DAX), and it sends the request to DynamoDB only if the items are not available in the DAX cluster (called a cache miss), so the response from DynamoDB is written to the DAX primary node and DAX returns the response to the application. AWS also offers a downloadable version of DynamoDB to save on provisioned throughput, data storage, and data transfer fees, which allows you to write and test applications without accessing the DynamoDB web service or using an Internet connection.</p>
<p class="indent"><span epub:type="pagebreak" id="page_386"/>A secondary index is designed to support your query operations to perform an index scan to retrieve the data instead of a table scan (i.e., querying the entire table). The GSI has the partition key and a sort key that can be different from the base table and the index span across all partitions. The LSI has the partition key that is similar to the base table, but it can have a different sort key and the index has the same partition key value. DynamoDB stream provides a stream of information about all the changes to your data in a DynamoDB table. Similar to triggers in the traditional relational database, the DynamoDB stream captures data whenever you create, update, or delete data items from the table. A stream can capture the before or after images of your data items. DynamoDB streams appear in the same sequence as the actual modifications and they appear only once in near-real time. The NoSQL Workbench for DynamoDB can be used to build new data models based on your existing data models, and you can also import and export the data model. NoSQL Workbench can be used as data model visualizer, where you visualize the access patterns of your query mapping without writing code. You can also manually add data or import data to your data model. You can use the graphical user interface to view and query your DynamoDB tables.</p>
<p class="indent">AWS-owned CMKs are used but are not stored in your AWS account. AWS owns and manages the CMKs to protect your data, so you don’t have the ability to view or audit key use. You don’t need to create, manage, and rotate the key regularly to protect the keys, and you are not charged a monthly fee or a usage fee for AWS-owned CMKs. You can use AWS-managed CMKs, where the CMKs are in your account but they are created and managed on your behalf by AWS. You can also use customer-managed CMKs, where you create, own, and manage the CMKs in your AWS account. You have full responsibility and control over these CMKs if you need to establish and maintain the key policies, IAM policies, and rotating cryptographic material. You incur AWS KMS charges for using your own KMS key.</p>
<h4 class="h4" id="ch14lev2sec11">Exercises</h4>
<p class="noindent">The following exercises will help you practice creating and managing DynamoDB tables. You need to create an AWS account, as explained earlier, before performing these exercises. You can use the Free Tier when launching AWS resources, but make sure to terminate them at the end.</p>
<h5 class="h5">Exercise 14-1: Create a DynamoDB Table Using the AWS Management Console</h5>
<p class="numbert"><strong>1.</strong> Use your AWS account e-mail address and password to sign in and then navigate to the AWS DynamoDB console at <a href="https://console.aws.amazon.com/dynamodb/">https://console.aws.amazon.com/dynamodb/</a>.</p>
<p class="number"><strong>2.</strong> Verify the AWS region by using the Region selector in the upper-right corner of the page.</p>
<p class="number"><strong>3.</strong> From the navigation pane on the left, choose DynamoDB.</p>
<p class="number"><strong>4.</strong> From the navigation pane, choose Dashboard.</p>
<p class="number"><strong>5.</strong> From the center of the page, choose Create Table.</p>
<p class="number"><strong>6.</strong> <span epub:type="pagebreak" id="page_387"/>For the table name, enter your new table name as <strong>Employee</strong>.</p>
<p class="number"><strong>7.</strong> For the partition key, enter the key as <strong>EMP_ID</strong> and select the data type as Number from the dropdown.</p>
<p class="number"><strong>8.</strong> Select the checkbox to choose Add Sort Key.</p>
<p class="number"><strong>9.</strong> Enter <strong>EMP_Name</strong> as the sort key and select the data type as String from the dropdown menu.</p>
<p class="number1"><strong>10.</strong> Select the checkbox for Use Default Settings</p>
<p class="number1"><strong>11.</strong> Add a tag for the key/value pair, with <strong>name</strong> as the key and <strong>Employee</strong> as the value.</p>
<p class="number1"><strong>12.</strong> Click Create to create the table.</p>
<h5 class="h5">Exercise 14-2: Write to the DynamoDB Table Using the AWS Management Console</h5>
<p class="numbert"><strong>1.</strong> Use your AWS account e-mail address and password to sign in and then navigate to the AWS DynamoDB console at <a href="https://console.aws.amazon.com/dynamodb/">https://console.aws.amazon.com/dynamodb/</a>.</p>
<p class="number"><strong>2.</strong> Verify the AWS region by using the Region selector in the upper-right corner of the page.</p>
<p class="number"><strong>3.</strong> From the navigation pane on the left, choose DynamoDB Tables.</p>
<p class="number"><strong>4.</strong> From the list of tables, choose the Employee table.</p>
<p class="number"><strong>5.</strong> Then choose the Items tab for the Employee table.</p>
<p class="number"><strong>6.</strong> Click on the Items tab and choose Create Item.</p>
<p class="number"><strong>7.</strong> Click the + symbol next to EMP_Name.</p>
<p class="number"><strong>8.</strong> Choose Append, and then choose String and name the field <strong>Job_Name</strong>.</p>
<p class="number"><strong>9.</strong> Repeat this process to create a string with the name <strong>Department</strong>.</p>
<p class="number1"><strong>10.</strong> For EMP_ID, enter <strong>10001</strong> as the value.</p>
<p class="number1"><strong>11.</strong> For EMP_Name, enter <strong>Jack Ryan</strong>.</p>
<p class="number1"><strong>12.</strong> For Job_Name, enter <strong>Developer</strong>.</p>
<p class="number1"><strong>13.</strong> For Department, enter <strong>Cloud</strong>.</p>
<p class="number1"><strong>14.</strong> Click Save.</p>
<h5 class="h5">Exercise 14-3: Read from the DynamoDB Table Using the AWS Management Console</h5>
<p class="numbert"><strong>1.</strong> Use your AWS account e-mail address and password to sign in and then navigate to the AWS DynamoDB console at <a href="https://console.aws.amazon.com/dynamodb/">https://console.aws.amazon.com/dynamodb/</a>.</p>
<p class="number"><strong>2.</strong> Verify the AWS region by using the Region selector in the upper-right corner of the page.</p>
<p class="number"><strong>3.</strong> From the navigation pane on the left, choose DynamoDB tables.</p>
<p class="number"><span epub:type="pagebreak" id="page_388"/><strong>4.</strong> From the list of tables, choose the Employee table.</p>
<p class="number"><strong>5.</strong> Choose the Items tab for the Employee table.</p>
<p class="number"><strong>6.</strong> On the Items tab, you can view the list of items stored in the table, sorted by EMP_ID and EMP_Name. The first item in the list is sorted ascending by EMP_ID.</p>
<h5 class="h5">Exercise 14-4: Update Data in the DynamoDB Table Using the AWS Management Console</h5>
<p class="numbert"><strong>1.</strong> Use your AWS account e-mail address and password to sign in and then navigate to the AWS DynamoDB console at <a href="https://console.aws.amazon.com/dynamodb/">https://console.aws.amazon.com/dynamodb/</a>.</p>
<p class="number"><strong>2.</strong> Verify the AWS region by using the Region selector in the upper-right corner of the page.</p>
<p class="number"><strong>3.</strong> From the navigation pane on the left, choose DynamoDB tables.</p>
<p class="number"><strong>4.</strong> From the list of tables, choose the Employee table.</p>
<p class="number"><strong>5.</strong> Choose the Items tab for the Employee table.</p>
<p class="number"><strong>6.</strong> Choose the item whose EMP_ID is 10001 and EMP_Name value is Jack Ryan.</p>
<p class="number"><strong>7.</strong> Update the Job_Name value to <strong>Senior Developer</strong>, and then choose Save.</p>
<h5 class="h5">Exercise 14-5: Query the DynamoDB Table Using the AWS Management Console</h5>
<p class="numbert"><strong>1.</strong> Use your AWS account e-mail address and password to sign in and then navigate to the AWS DynamoDB console at <a href="https://console.aws.amazon.com/dynamodb/">https://console.aws.amazon.com/dynamodb/</a>.</p>
<p class="number"><strong>2.</strong> Verify the AWS region by using the Region selector in the upper-right corner of the page.</p>
<p class="number"><strong>3.</strong> From the navigation pane on the left, choose DynamoDB tables.</p>
<p class="number"><strong>4.</strong> From the list of tables, choose the Employee table.</p>
<p class="number"><strong>5.</strong> Choose the Items tab for the Employee table.</p>
<p class="number"><strong>6.</strong> Choose Query from the dropdown list.</p>
<h5 class="h5">Exercise 14-6: Scan the DynamoDB Table Using the AWS Management Console</h5>
<p class="numbert"><strong>1.</strong> Use your AWS account e-mail address and password to sign in and then navigate to the AWS DynamoDB console at <a href="https://console.aws.amazon.com/dynamodb/">https://console.aws.amazon.com/dynamodb/</a>.</p>
<p class="number"><strong>2.</strong> Verify the AWS region by using the Region selector in the upper-right corner of the page.</p>
<p class="number"><strong>3.</strong> From the navigation pane on the left, choose DynamoDB tables.</p>
<p class="number"><span epub:type="pagebreak" id="page_389"/><strong>4.</strong> From the list of tables, choose the Employee table.</p>
<p class="number"><strong>5.</strong> Choose the Items tab for the Employee table.</p>
<p class="number"><strong>6.</strong> Choose Scan from the dropdown list.</p>
<h4 class="h4" id="ch14lev2sec12">Questions</h4>
<p class="noindent">The following questions will help you gauge your understanding of the contents in this chapter. Read all the answers carefully because there might be more than one correct answer. Choose the best response for each question.</p>
<p class="numbert"><strong><a href="ch14.xhtml#rch14qa1" id="ch14qa1">1.</a></strong> Your application needs to store large volumes of semi-structured data and retrieve it with single-digit millisecond to microsecond latency. Which of the following NoSQL databases is suitable for your application?</p>
<p class="alphau"><strong>A.</strong> Amazon DynamoDB</p>
<p class="alphau"><strong>B.</strong> Amazon RDS</p>
<p class="alphau"><strong>C.</strong> Amazon S3</p>
<p class="alphau"><strong>D.</strong> Amazon EBS</p>
<p class="number"><strong><a href="ch14.xhtml#rch14qa2" id="ch14qa2">2.</a></strong> Which of the following keys uniquely identifies each item in an Amazon DynamoDB table to make sure no two items can have the same key?</p>
<p class="alphau"><strong>A.</strong> Sort key</p>
<p class="alphau"><strong>B.</strong> Foreign key</p>
<p class="alphau"><strong>C.</strong> Primary key</p>
<p class="alphau"><strong>D.</strong> Composite key</p>
<p class="number"><strong><a href="ch14.xhtml#rch14qa3" id="ch14qa3">3.</a></strong> Which of the following secondary indexes are supported in Amazon DynamoDB? (Choose two.)</p>
<p class="alphau"><strong>A.</strong> Regional secondary index has the same partition and sort key</p>
<p class="alphau"><strong>B.</strong> Global secondary index has a partition key and sort key that can be different from the base table</p>
<p class="alphau"><strong>C.</strong> Local secondary index has the same partition key as the table, but a different sort key</p>
<p class="alphau"><strong>D.</strong> State secondary index has the same sort key, but a different partition key</p>
<p class="number"><strong><a href="ch14.xhtml#rch14qa4" id="ch14qa4">4.</a></strong> Your application writes nearly 25 items in a transaction by using PutItem multiple times, consuming many network round trips. How can you reduce the latency and network round trips for multiple items?</p>
<p class="alphau"><strong>A.</strong> Use DynamoDB Accelerator (DAX)</p>
<p class="alphau"><strong>B.</strong> Use BatchGetItem to write multiple items</p>
<p class="alphau"><strong>C.</strong> Use GetItem to write items</p>
<p class="alphau"><strong>D.</strong> Use BatchWriteItem instead of PutItem to write bulk records</p>
<p class="number"><span epub:type="pagebreak" id="page_390"/><strong><a href="ch14.xhtml#rch14qa5" id="ch14qa5">5.</a></strong> Your company’s compliance policy requires that all data modifications are captured for audit purposes in your Amazon DynamoDB database. How can you capture the events that are happening in near real-time during any add, update, and delete operation?</p>
<p class="alphau"><strong>A.</strong> Enable Amazon DynamoDB Accelerator (DAX)</p>
<p class="alphau"><strong>B.</strong> Create a global table to capture the events</p>
<p class="alphau"><strong>C.</strong> Enable Amazon DynamoDB streams to capture before and after images of your data</p>
<p class="alphau"><strong>D.</strong> Enable Amazon DynamoDB transactions to capture the events automatically</p>
<p class="number"><strong><a href="ch14.xhtml#rch14qa6" id="ch14qa6">6.</a></strong> Which of the following are control-plane operations that can be used to create and manage Amazon DynamoDB tables? (Choose three.)</p>
<p class="alphau"><strong>A.</strong> CreateTable can be used to create a new table and indexes and to enable Amazon DynamoDB streams of a table</p>
<p class="alphau"><strong>B.</strong> UpdateTable can be used to modify the table and indexes and to modify Amazon DynamoDB streams of a table</p>
<p class="alphau"><strong>C.</strong> DeleteTable can be used to remove a table and its objects from the Amazon DynamoDB table</p>
<p class="alphau"><strong>D.</strong> PutItem can be used to write a single item to an Amazon DynamoDB table</p>
<p class="number"><strong><a href="ch14.xhtml#rch14qa7" id="ch14qa7">7.</a></strong> A developer accidently ran a test script in a production database and deleted 12 tables and updated data from 46 tables at 2 <span class="smallcaps">p.m</span>. today from the Amazon DynamoDB database that has point-in-time recovery enabled for 35 days. How can you fix this quickly and restore those 58 tables in production?</p>
<p class="alphau"><strong>A.</strong> You can restore all the tables using LatestRestorableDateTime to just before 2 <span class="smallcaps">p.m</span>. today.</p>
<p class="alphau"><strong>B.</strong> You can restore only the 12 tables but not those 46 tables that were updated.</p>
<p class="alphau"><strong>C.</strong> You can restore only 46 tables but not those 12 tables that were deleted.</p>
<p class="alphau"><strong>D.</strong> It is not possible to restore any tables; you need to use yesterday’s manual backup to restore the entire database.</p>
<p class="number"><strong><a href="ch14.xhtml#rch14qa8" id="ch14qa8">8.</a></strong> You have a large online shopping website, and your customers are spread across US East/West Coast, Europe, and Asia Pacific regions. At the moment you have eight identical DynamoDB tables for your products in eight different AWS regions that are entirely separate from each other. You have managed a replication solution to keep all the data changes in sync, but it’s time-consuming and requires a lot of labor. Now you need to add four more regions and want to avoid this time-consuming and labor-intensive replication effort. Which feature of Amazon DynamoDB solves this issue?</p>
<p class="alphau"><strong>A.</strong> Amazon DynamoDB Accelerator (DAX)</p>
<p class="alphau"><strong>B.</strong> Amazon DynamoDB global tables</p>
<p class="alphau"><strong>C.</strong> Amazon DynamoDB streams</p>
<p class="alphau"><strong>D.</strong> Amazon DynamoDB transactions</p>
<p class="number"><span epub:type="pagebreak" id="page_391"/><strong><a href="ch14.xhtml#rch14qa9" id="ch14qa9">9.</a></strong> Amazon DynamoDB supports different isolation levels to ensure that the results of multiple concurrent operations are the same, as if only one operation in the transaction is occurring and ensures the read operations always return committed values for an item. Which of the following isolations are supported in Amazon DynamoDB? (Choose two.)</p>
<p class="alphau"><strong>A.</strong> Parallelable</p>
<p class="alphau"><strong>B.</strong> Write-committed</p>
<p class="alphau"><strong>C.</strong> Serializable</p>
<p class="alphau"><strong>D.</strong> Read-committed</p>
<p class="number1"><strong><a href="ch14.xhtml#rch14qa10" id="ch14qa10">10.</a></strong> You want to enable encryption when creating a new Amazon DynamoDB table. Which of the following encryption options are available? (Choose three.)</p>
<p class="alphau"><strong>A.</strong> Server-managed SMK, where the EC2 server owns and manages the key</p>
<p class="alphau"><strong>B.</strong> AWS-owned CMK, where the key is owned by DynamoDB</p>
<p class="alphau"><strong>C.</strong> AWS-managed CMK, where the key is stored in your account and is managed by AWS KMS</p>
<p class="alphau"><strong>D.</strong> Customer-managed CMK, where the key is stored in your account and is created, owned, and managed by you.</p>
<h4 class="h4" id="ch14lev2sec13">Answers</h4>
<p class="numbert"><strong><a href="ch14.xhtml#ch14qa1" id="rch14qa1">1.</a> A.</strong> You can use Amazon DynamoDB to retrieve the data with single-digit millisecond to microsecond latency.</p>
<p class="number"><strong><a href="ch14.xhtml#ch14qa2" id="rch14qa2">2.</a> C.</strong> Amazon DynamoDB uses a primary key to uniquely store and identify the items in a table.</p>
<p class="number"><strong><a href="ch14.xhtml#ch14qa3" id="rch14qa3">3.</a> B, C.</strong> Amazon DynamoDB supports a global secondary index and local secondary index.</p>
<p class="number"><strong><a href="ch14.xhtml#ch14qa4" id="rch14qa4">4.</a> D.</strong> You need to use BatchWriteItem instead of PutItem for writing bulk records.</p>
<p class="number"><strong><a href="ch14.xhtml#ch14qa5" id="rch14qa5">5.</a> C.</strong> You can enable Amazon DynamoDB streams to capture before and after images of your data.</p>
<p class="number"><strong><a href="ch14.xhtml#ch14qa6" id="rch14qa6">6.</a> A, B, C.</strong> CreateTable, UpdateTable, and DeleteTable are the control-plane operations available in Amazon DynamoDB.</p>
<p class="number"><strong><a href="ch14.xhtml#ch14qa7" id="rch14qa7">7.</a> A.</strong> You can restore all the tables using LatestRestorableDateTime to just before 2 <span class="smallcaps">p.m</span>. today.</p>
<p class="number"><strong><a href="ch14.xhtml#ch14qa8" id="rch14qa8">8.</a> B.</strong> Amazon DynamoDB global tables can manage the replication across regions for you.</p>
<p class="number"><strong><a href="ch14.xhtml#ch14qa9" id="rch14qa9">9.</a> C, D.</strong> Amazon DynamoDB supports serializable and read-committed isolation levels.</p>
<p class="number1"><strong><a href="ch14.xhtml#ch14qa10" id="rch14qa10">10.</a> B, C, D.</strong> Amazon DynamoDB supports AWS-owned CMKs, AWS-managed CMKs, and customer-managed CMKs.</p>
<h3 class="h3" id="ch14lev1sec23"><span epub:type="pagebreak" id="page_392"/>Additional Resources</h3>
<p class="bullett">• <strong>Amazon DynamoDB Documentation</strong>   There is no place like official AWS documentation to get the latest and most up-to-date information about Amazon DynamoDB database.</p>
<p class="bulletc"><img alt="images" src="p0392-01.jpg"/></p>
<p class="bulleta">• <strong>Amazon DynamoDB AWS re:Invent videos</strong>   This blog lists all useful videos and slide decks from AWS re:Invent 2019.</p>
<p class="bulletc"><img alt="images" src="p0392-02.jpg"/></p>
<p class="bulleta">• <strong>Getting Started with Amazon DynamoDB</strong>   This blog is the one-stop shop to get you quickly get started with Amazon DynamoDB by creating a table, adding items, and querying.</p>
<p class="bulletc"><img alt="images" src="p0392-03.jpg"/></p>
<p class="bulleta">• <strong>Amazon DynamoDB in 2019</strong>   This is another interesting blog that lists all the major updates for Amazon DynamoDB in 2019.</p>
<p class="bulletc"><img alt="images" src="p0392-04.jpg"/></p>
<p class="bulleta">• <strong>Secure Your Data in Amazon DynamoDB</strong>   This blog explains step by step the procedures and best practices to secure your sensitive data in Amazon DynamoDB.</p>
<p class="bulletc"><img alt="images" src="p0392-05.jpg"/></p>
</section>
</body>
</html>